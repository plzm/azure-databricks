{"cells":[{"cell_type":"code","source":["# Get iterable file list. Flattens hierarchical folder/file structure.\ndef GetFilesRecursive(rootPath):\n  final_list = []\n\n  for directoryItem in dbutils.fs.ls(rootPath):\n    directoryItemPathClean = directoryItem.path.replace(\"%25\", \"%\").replace(\"%25\", \"%\")\n    \n    if directoryItem.isDir() == True:\n      final_list = final_list + GetFilesRecursive(directoryItemPathClean)\n    else:\n      final_list.append(directoryItemPathClean)\n  \n  return final_list;"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Delete Spark job residual files (_SUCCESS, _start*, _committed*) down the folder/file hierarchy\n\nimport os\n\ndef CleanupSparkJobFiles(parquetFolderPath):\n  file_paths = GetFilesRecursive(parquetFolderPath)\n  \n  for file_path in file_paths:\n    # Get just the file name\n    file_name = os.path.basename(file_path)\n    # print(file_name)\n    \n    if file_name.startswith(\"_\"):\n      # Temp job file - delete it\n      dbutils.fs.rm(file_path)\n    # elif file_name.endswith(\".parquet\"):\n      # Data file - no op\n    # else:\n      # Something else - no op\n"],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"adb_1_functions","notebookId":3551257439585118},"nbformat":4,"nbformat_minor":0}
