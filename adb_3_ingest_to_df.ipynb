{"cells":[{"cell_type":"markdown","source":["#### References:<br>\nhttps://docs.azuredatabricks.net/user-guide/importing-data.html<br>\nhttps://docs.azuredatabricks.net/spark/latest/faq/join-two-dataframes-duplicated-column.html<br>\n\nhttps://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame<br>"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["source_file = \"/mnt/hack/csv/sample/dat202/airports.csv\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["#### With header, and schema inference"],"metadata":{}},{"cell_type":"code","source":["df_inferred = spark\\\n    .read\\\n    .format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .load(source_file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["#### With header, and explicit schema"],"metadata":{}},{"cell_type":"code","source":["# Define the schema explicitly\n\ndata_schema = StructType([\n  StructField(\"airport_id\", IntegerType(), True),\n  StructField(\"city\", StringType(), True),\n  StructField(\"state\", StringType(), True),\n  StructField(\"name\", StringType(), True)\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Read the data into a dataframe, explicitly specifying the schema we defined above\n\ndf_explicit = spark\\\n    .read\\\n    .format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .schema(data_schema)\\\n    .load(source_file)"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"adb_3_ingest_to_df","notebookId":2750624936770996},"nbformat":4,"nbformat_minor":0}
