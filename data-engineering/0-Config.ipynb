{"cells":[{"cell_type":"code","source":["import datetime"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["#### Get secrets from Secret Scope\n\nHow to set up an AKV-backed Databricks secret scope: https://docs.azuredatabricks.net/user-guide/secrets/secret-scopes.html#create-an-azure-key-vault-backed-secret-scope"],"metadata":{}},{"cell_type":"code","source":["# ADLS gen2 storage account key\nstorageAccountKey = dbutils.secrets.get(scope = \"secrets\", key = \"StorageAccountKey\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["#### Variables\n\nNothing sensitive should be here - only variables/info that is fine to be visible/open"],"metadata":{}},{"cell_type":"code","source":["storageAccountName = \"\"\n\n# Note we are using the ADLS gen2 ABFS driver, not WASB/S.\nadls2uri_raw = \"abfss://raw@\" + storageAccountName + \".dfs.core.windows.net/\"\nadls2uri_staging1 = \"abfss://staging1@\" + storageAccountName + \".dfs.core.windows.net/\"\nadls2uri_curated = \"abfss://curated@\" + storageAccountName + \".dfs.core.windows.net/\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### Connect to ADLS gen 2 file system\n\nWe will access the ADLS gen2 file system directly, as that can be done without a mount point (see below)\nSee:\n- https://docs.databricks.com/spark/latest/data-sources/azure/azure-datalake-gen2.html#access-an-azure-data-lake-storage-gen2-account-directly\n\nNote: we could create a mount point (e.g. /mnt/azure/) but that requires a Service Principal, which requires Azure AD access to create.\nSee:\n- https://docs.databricks.com/spark/latest/data-sources/azure/azure-datalake-gen2.html#mount-an-azure-data-lake-storage-gen2-filesystem-with-dbfs\n- https://docs.databricks.com/spark/latest/data-sources/azure/azure-datalake-gen2.html#requirements-azure-data-lake\n- https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"],"metadata":{}},{"cell_type":"code","source":["# Set Spark config to point at the ADLS gen2 storage account\nspark.conf.set(\"fs.azure.account.key.\" + storageAccountName + \".dfs.core.windows.net\", storageAccountKey)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Prepare date variables we'll need\n\n# ASSUMPTION - we have data in a folder with YESTERDAY'S date. Adjust as obviously needed.\n\n# Start with current date and subtract a day\nnow = datetime.datetime.now() + datetime.timedelta(days=-1)\n\n# Get year, month, and day into separate vars\nint_year = now.year\nint_month = now.month\nint_day = now.day\n\n# Get string formatted versions of these with leading zeroes for month and day (for eventual output paths)\nstr_year = str(int_year)\nstr_month = \"{:02d}\".format(int_month)\nstr_day = \"{:02d}\".format(int_day)\n\n# Prepare path chunk for yyyy/mm/dd so we don't have to keep doing this below\npath_chunk_date = str_year + \"/\" + str_month + \"/\" + str_day\nprint (path_chunk_date)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"0-Config","notebookId":3265516488115426},"nbformat":4,"nbformat_minor":0}
